\section{Conclusion}
We have explored two graphical models, HMM and MEMM, in the POS tagging application domain. Through implementation of both models, we gained deeper understanding for the learning and predicting mechanisms behind each model and how to realize it from data parsing, to constructing the models, and lastly learn and predict using them. We ran both models through the Brown and WSJ corpora, we were able get satisfactory results for HMM but not MEMM. This is mainly due to the insufficient training data and the relatively long time compared to HMM to train it. During the implementation process, we learned that smoothing is a key feature to have for both models to produce meaningful prediction results, even rudimentary additive smoothing is powerful enough to produce viable results.

HMM and MEMM are just two of numerous models used for POS tagging. Even though both look similar on the surface, the implementation of the learning proved to be drastically different. For future work, in addition to training the model with more data and apply additional optimization techniques, we hope to extend MEMM to incorporate more features, especially more sophisticated ones that involves more than one state or observation, to see performance differences.

Overall, we find this to be an invaluable learning experience to be exposed to strengths and weaknesses of graphical models by implementation and an important stepping-stone to implementing more sophisticated graphical models.
