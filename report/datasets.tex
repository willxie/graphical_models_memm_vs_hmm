\section{Datasets}
\label{sec:datasets}
For this investigation we focus on two corpora: the Wall Street Journal (WSJ) corpus and the Brown corpus. The WSJ corpus is a collection of 2,499 articles from the Wall Street Journal newspaper from 1987 to 1989. It has approximately 3 million words and was tagged by using statistically-based methods. This corpus has a total of 82 possible POS tags~\cite{wsjCorpus}. On the other hand, the Brown corpus is a manually tagged collection of 500 text documents sampled from 1961 and contains around a million words. It uses 93 POS tags. It is gathered from various sources and contains numerous topics such as fiction, press, and lore~\cite{brownCorpus}. Due to the difference in word counts, for this project, we only use around a million words from WSJ corpus.

These two corpora are chosen because they are standards of the field, making them easy to obtain. Furthermore, they allow us to compare our results to the rest of the NLP literature. In addition, they represent different distributions of words. Since the WSJ corpus targets a specific demographics, the range of topics it covers is relatively narrow and should contain more specialized words. Thus, it is reasonable to expect that the word distribution in this corpus to be narrower than other corpora. On the other hand, we expect the Brown corpus to represent a more general distribution on word choices. Therefore, by using two corpora with different properties, we are able to gauge the performance of the models in a broader set of situations in which POS tagging is used.

\begin{figure}[ht]
 \begin{Verbatim}[frame=single,framesep=5mm]
\[ He/PRP \]
tried/VBD to/TO ignore/VB
\[ what/WP \]

\[ his/PRP\$ own/JJ common/JJ sense/NN \]
told/VBD
\[ him/PRP \]
,/, but/CC
\[ it/PRP \]

\[ was/VBD n't/RB possible/JJ \]
;/: ;/:
\[ her/PRP$ motives/NNS \]
were/VBD too/RB blatant/JJ ./.
\end{Verbatim}
\caption{Example sentence from the Brown Corpus~\cite{brownCorpus} \label{brownExample}}
\end{figure}
