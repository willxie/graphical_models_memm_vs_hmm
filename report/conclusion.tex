\section{Conclusion}
We have explored two graphical models, HMM and MEMM, in the POS tagging application domain. Through implementation of both models, we gained deeper understanding for the learning and decoding mechanisms behind each model and how to realize them from data parsing, to constructing the models, and lastly learn and predict using them. We ran both models through the Brown and WSJ corpora, we were able get satisfactory results for HMM but not MEMM. This is mainly due to insufficient training data and the relatively long training time compared to HMM. During the implementation process we learned that smoothing is a key feature to have for both models in order to produce meaningful results. Even with rudimentary techniques such as additive smoothing, it is powerful enough to produce viable results.

HMM and MEMM are just two of numerous models used for POS tagging. Even though both look similar on the surface, the implementation of the learning proved to be drastically different. For future work, we plan to train the models with more data and apply additional optimization techniques. We also hope to extend MEMM to incorporate more features, especially more sophisticated ones that involves more than one state or observation, to see performance differences.

Overall, we find project to be an invaluable learning experience to be
exposed to strengths and weaknesses of graphical models by implementation and an important stepping-stone to understanding and implementing more sophisticated graphical models.
